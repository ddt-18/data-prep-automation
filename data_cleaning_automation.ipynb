{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9594aa97-8c7c-4534-bf7d-f267c9e1e8fe",
   "metadata": {},
   "source": [
    "# üöÄ Quickstart: How to Use This Notebook\n",
    "\n",
    "1. Put your datasets (CSV or Excel) in a folder.  \n",
    "   Example: `C:/Users/You/Documents/Datasets`\n",
    "\n",
    "2. Update the `DATA_FOLDER` path in the CONFIGURATION section below\n",
    "   to point to that folder.\n",
    "\n",
    "3. Run the notebook cells step by step.\n",
    "\n",
    "4. What you‚Äôll get in the `output` folder:\n",
    "   - ‚úÖ Cleaned dataset (Excel file)\n",
    "   - üìä Profiling report (HTML with stats & visuals)\n",
    "   - üìà Charts (PNG images)\n",
    "\n",
    "üí° Tip: If `DATA_FOLDER` is left empty/None, the notebook will prompt you\n",
    "to enter a folder path interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd985f6-eafb-4167-abc8-051edb0ee83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Suppress warnings from matplotlib and pandas for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATION\n",
    "# -----------------------------\n",
    "\n",
    "# =============================\n",
    "# ‚ö†Ô∏è How to use this section:\n",
    "# - Change `DATA_FOLDER` to where your datasets actually live.\n",
    "# - Change `OUTPUT_FOLDER` if you want results saved elsewhere.\n",
    "# - Set SHOW_PREVIEW = False if you don‚Äôt want sample rows printed.\n",
    "# - Usually you don‚Äôt need to touch EXCLUDE_PATTERNS unless you \n",
    "#   notice weird columns in your plots.\n",
    "# =============================\n",
    "\n",
    "# Path to the folder where your datasets are stored\n",
    "DATA_FOLDER = r\"C:\\Users\\Admin\\Documents\\Automation\\Datasets\"  # <-- IMPORTANT: SET YOUR DATA FOLDER PATH\n",
    "\n",
    "# Path where all outputs (cleaned files, plots, reports) will be saved\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "\n",
    "# Whether to show quick previews (first 5 rows) when loading data\n",
    "SHOW_PREVIEW = True \n",
    "\n",
    "# Columns to EXCLUDE automatically from visualization (too generic / irrelevant)\n",
    "EXCLUDE_PATTERNS = ['id', 'desc', 'number', 'phone', 'contact', 'name']\n",
    "\n",
    "# =============================================================================\n",
    "# MODULAR FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def list_and_select_files(data_folder: str) -> list:\n",
    "    \"\"\"\n",
    "    Scans the data folder for datasets, displays them, and prompts the user\n",
    "    to select one or more files for processing.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): The path to the folder containing datasets.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of full file paths for the selected datasets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        files = [f for f in os.listdir(data_folder) if f.lower().endswith((\".xlsx\", \".xls\", \".csv\"))]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERROR: The specified data folder does not exist: {data_folder}\")\n",
    "        return []\n",
    "\n",
    "    if not files:\n",
    "        print(f\"‚ùå No datasets found in: {data_folder}\")\n",
    "        return []\n",
    "\n",
    "    print(\"\\nAvailable datasets:\")\n",
    "    for i, f in enumerate(files, 1):\n",
    "        print(f\"  {i}. {f}\")\n",
    "\n",
    "    choice_str = input(\n",
    "        \"\\nEnter number(s) of dataset(s) to process, comma-separated (e.g., 1,3 or 2) [default: last]: \"\n",
    "    ).strip()\n",
    "\n",
    "    selected_files = []\n",
    "    if not choice_str:\n",
    "        selected_files.append(os.path.join(data_folder, files[-1])) # Default to last file\n",
    "    else:\n",
    "        try:\n",
    "            choices = [int(c.strip()) - 1 for c in choice_str.split(\",\")]\n",
    "            selected_files = [os.path.join(data_folder, files[i]) for i in choices]\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"‚ö†Ô∏è Invalid input. Defaulting to the last dataset.\")\n",
    "            selected_files.append(os.path.join(data_folder, files[-1]))\n",
    "\n",
    "    return selected_files\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Loads a dataset from a given file path (CSV or Excel).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The full path to the data file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: A pandas DataFrame if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚è≥ Loading data from: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        if file_path.lower().endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "        print(f\"‚úÖ Loaded successfully with shape {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {os.path.basename(file_path)}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_cleaning_choices(df_columns: list) -> dict:\n",
    "    \"\"\"\n",
    "    Asks the user for their preferred data cleaning methods and optional column selection for visualizations.\n",
    "\n",
    "    Args:\n",
    "        df_columns (list): List of DataFrame columns to validate visualization choices.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the user's cleaning and visualization choices.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Data Cleaning Options ---\")\n",
    "    \n",
    "    # Choice for handling missing values\n",
    "    while True:\n",
    "        mv_choice = input(\"How to handle missing values?\\n  [1] Drop rows with missing values\\n  [2] Fill with mean (numeric) / mode (text)\\n  [3] Do nothing\\n  Enter your choice (1/2/3): \").strip()\n",
    "        if mv_choice in ['1', '2', '3']:\n",
    "            break\n",
    "        print(\"‚ö†Ô∏è Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "    # Choice for handling duplicates\n",
    "    while True:\n",
    "        dd_choice = input(\"Drop duplicate rows? (y/n): \").strip().lower()\n",
    "        if dd_choice in ['y', 'n']:\n",
    "            break\n",
    "        print(\"‚ö†Ô∏è Invalid choice. Please enter y or n.\")\n",
    "\n",
    "    # Choice for manual column selection for visualizations\n",
    "    print(\"\\n--- Visualization Options ---\")\n",
    "    print(f\"Available columns: {df_columns}\")\n",
    "    bar_cols = []\n",
    "    pie_cols = []\n",
    "    while True:\n",
    "        manual_choice = input(\"Manually select columns for visualizations? (y/n): \").strip().lower()\n",
    "        if manual_choice in ['y', 'n']:\n",
    "            break\n",
    "        print(\"‚ö†Ô∏è Invalid choice. Please enter y or n.\")\n",
    "\n",
    "    if manual_choice == 'y':\n",
    "        # Bar chart columns\n",
    "        bar_input = input(\"Enter column names for bar charts (comma-separated, e.g., Vehicle_Type,City) or 'none': \").strip()\n",
    "        if bar_input.lower() != 'none':\n",
    "            bar_cols = [col.strip() for col in bar_input.split(\",\")]\n",
    "            bar_cols = [col for col in bar_cols if col in df_columns]\n",
    "            if not bar_cols:\n",
    "                print(\"‚ö†Ô∏è No valid columns selected for bar charts. Using auto-selection.\")\n",
    "            else:\n",
    "                print(f\"Selected bar chart columns: {bar_cols}\")\n",
    "\n",
    "        # Pie chart columns\n",
    "        pie_input = input(\"Enter column names for pie charts (comma-separated, e.g., Booking_Status,Payment_Method) or 'none': \").strip()\n",
    "        if pie_input.lower() != 'none':\n",
    "            pie_cols = [col.strip() for col in pie_input.split(\",\")]\n",
    "            pie_cols = [col for col in pie_cols if col in df_columns]\n",
    "            if not pie_cols:\n",
    "                print(\"‚ö†Ô∏è No valid columns selected for pie charts. Using auto-selection.\")\n",
    "            else:\n",
    "                print(f\"Selected pie chart columns: {pie_cols}\")\n",
    "\n",
    "    choices_map = {'1': 'drop', '2': 'fill', '3': 'none'}\n",
    "    return {\n",
    "        'missing_values': choices_map[mv_choice],\n",
    "        'drop_duplicates': True if dd_choice == 'y' else False,\n",
    "        'bar_columns': bar_cols,\n",
    "        'pie_columns': pie_cols\n",
    "    }\n",
    "\n",
    "\n",
    "def clean_data(df: pd.DataFrame, choices: dict) -> tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Cleans the DataFrame based on the user's choices and returns a mapping of original to cleaned column names.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        choices (dict): A dictionary of cleaning options.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Cleaned DataFrame, dictionary mapping original to cleaned column names).\n",
    "    \"\"\"\n",
    "    print(\"‚è≥ Applying cleaning rules...\")\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Store original column names\n",
    "    original_columns = df_cleaned.columns.tolist()\n",
    "    \n",
    "    # 1. Handle Duplicates\n",
    "    if choices['drop_duplicates']:\n",
    "        initial_rows = len(df_cleaned)\n",
    "        df_cleaned.drop_duplicates(inplace=True)\n",
    "        print(f\"  - Dropped {initial_rows - len(df_cleaned)} duplicate rows.\")\n",
    "\n",
    "    # 2. Handle Missing Values\n",
    "    if choices['missing_values'] == 'drop':\n",
    "        initial_rows = len(df_cleaned)\n",
    "        df_cleaned.dropna(inplace=True)\n",
    "        print(f\"  - Dropped {initial_rows - len(df_cleaned)} rows with missing values.\")\n",
    "    elif choices['missing_values'] == 'fill':\n",
    "        for col in df_cleaned.columns:\n",
    "            if df_cleaned[col].isnull().any():\n",
    "                if pd.api.types.is_numeric_dtype(df_cleaned[col]):\n",
    "                    df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].mean())\n",
    "                else:\n",
    "                    df_cleaned[col] = df_cleaned[col].fillna(\n",
    "                        df_cleaned[col].mode().iloc[0] if not df_cleaned[col].mode().empty else \"Unknown\"\n",
    "                    )\n",
    "        print(\"  - Filled missing values with mean/mode.\")\n",
    "\n",
    "    # 3. Standardize Column Names\n",
    "    cleaned_columns = [c.strip().replace(\" \", \"_\") for c in df_cleaned.columns]\n",
    "    column_mapping = dict(zip(original_columns, cleaned_columns))\n",
    "    df_cleaned.columns = cleaned_columns\n",
    "    print(\"  - Standardized column names.\")\n",
    "\n",
    "    # 4. Attempt to convert data types\n",
    "    def try_to_numeric(series):\n",
    "        try:\n",
    "            return pd.to_numeric(series)\n",
    "        except (ValueError, TypeError):\n",
    "            return series\n",
    "    df_cleaned = df_cleaned.apply(try_to_numeric)\n",
    "    print(\"  - Converted applicable columns to numeric types.\")\n",
    "    \n",
    "    print(f\"‚úÖ Cleaning complete. New shape: {df_cleaned.shape}\")\n",
    "    return df_cleaned, column_mapping\n",
    "\n",
    "\n",
    "def generate_visualizations(df: pd.DataFrame, base_filename: str, output_folder: str, bar_columns: list, pie_columns: list):\n",
    "    \"\"\"\n",
    "    Generates 2-4 visualizations (1-2 bar charts for top categories, 1-2 pie charts for distributions) \n",
    "    using user-selected columns or automatic selection.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to visualize (preferably cleaned).\n",
    "        base_filename (str): The base name for output files.\n",
    "        output_folder (str): The main output directory.\n",
    "        bar_columns (list): User-selected columns for bar charts, if any.\n",
    "        pie_columns (list): User-selected columns for pie charts, if any.\n",
    "    \"\"\"\n",
    "    print(\"üìä Generating visualizations...\")\n",
    "    plot_folder = os.path.join(output_folder, f\"{base_filename}_plots\")\n",
    "    os.makedirs(plot_folder, exist_ok=True)\n",
    "\n",
    "    # Get categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Filter out excluded columns based on patterns for auto-selection\n",
    "    filtered_cols = [\n",
    "        col for col in categorical_cols\n",
    "        if not any(pat.lower() in col.lower() for pat in EXCLUDE_PATTERNS)\n",
    "    ]\n",
    "\n",
    "    # Initialize bar and pie columns\n",
    "    selected_bar_cols = bar_columns if bar_columns else []\n",
    "    selected_pie_cols = pie_columns if pie_columns else []\n",
    "\n",
    "    # Automatic selection if no user input\n",
    "    if not selected_bar_cols and not selected_pie_cols:\n",
    "        # Pie candidates: low cardinality (2-10 unique values) for distributions\n",
    "        pie_candidates = sorted([col for col in filtered_cols if 2 <= df[col].nunique() <= 10])\n",
    "        # Bar candidates: moderate cardinality (5-50 unique values) for top categories\n",
    "        bar_candidates = sorted([col for col in filtered_cols if 5 <= df[col].nunique() <= 100])\n",
    "\n",
    "        # Select up to 2 for pie\n",
    "        selected_pie_cols = pie_candidates[:2]\n",
    "        # Select up to 2 for bar, preferring those not in pie\n",
    "        selected_bar_cols = [col for col in bar_candidates if col not in selected_pie_cols][:2]\n",
    "        # Fallback: If no bar candidates, use remaining filtered cols with >1 unique\n",
    "        if len(selected_bar_cols) < 1:\n",
    "            remaining = [col for col in filtered_cols if col not in selected_pie_cols and df[col].nunique() > 1]\n",
    "            selected_bar_cols = sorted(remaining)[:2]\n",
    "\n",
    "    visual_count = 0\n",
    "\n",
    "    # Generate 1-2 Bar Charts (top 10 values)\n",
    "    for col in selected_bar_cols[:2]:  # Limit to 2\n",
    "        if col in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_10 = df[col].value_counts().nlargest(10)\n",
    "            sns.barplot(x=top_10.values, y=top_10.index).set_title(f'Top 10 {col}')\n",
    "            plt.xlabel('Count')\n",
    "            plt.ylabel(col)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_folder, f'bar_{col}.png'))\n",
    "            plt.close()\n",
    "            visual_count += 1\n",
    "            print(f\"  - Generated bar chart for {col}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Skipping bar chart for {col}: column not found\")\n",
    "\n",
    "    # Generate 1-2 Pie Charts\n",
    "    for col in selected_pie_cols[:2]:  # Limit to 2\n",
    "        if col in df.columns and 2 <= df[col].nunique() <= 10:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            value_counts = df[col].value_counts()\n",
    "            plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.savefig(os.path.join(plot_folder, f'pie_{col}.png'))\n",
    "            plt.close()\n",
    "            visual_count += 1\n",
    "            print(f\"  - Generated pie chart for {col}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Skipping pie chart for {col}: {'column not found' if col not in df.columns else 'invalid number of unique values'}\")\n",
    "\n",
    "    # Fallback: Auto-generate if fewer than 2 visuals\n",
    "    if visual_count < 2 and not (selected_bar_cols or selected_pie_cols):\n",
    "        # Pie candidates\n",
    "        pie_candidates = sorted([col for col in filtered_cols if 2 <= df[col].nunique() <= 10])\n",
    "        for col in pie_candidates[:2]:\n",
    "            if visual_count >= 4:\n",
    "                break\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            value_counts = df[col].value_counts()\n",
    "            plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.savefig(os.path.join(plot_folder, f'pie_{col}.png'))\n",
    "            plt.close()\n",
    "            visual_count += 1\n",
    "            print(f\"  - Generated pie chart for {col} (auto-selected)\")\n",
    "\n",
    "        # Bar candidates\n",
    "        bar_candidates = sorted([col for col in filtered_cols if 5 <= df[col].nunique() <= 100 and col not in pie_candidates])\n",
    "        for col in bar_candidates[:2]:\n",
    "            if visual_count >= 4:\n",
    "                break\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            top_10 = df[col].value_counts().nlargest(10)\n",
    "            sns.barplot(x=top_10.values, y=top_10.index).set_title(f'Top 10 {col}')\n",
    "            plt.xlabel('Count')\n",
    "            plt.ylabel(col)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(plot_folder, f'bar_{col}.png'))\n",
    "            plt.close()\n",
    "            visual_count += 1\n",
    "            print(f\"  - Generated bar chart for {col} (auto-selected)\")\n",
    "\n",
    "    if visual_count == 0:\n",
    "        print(\"  ‚ö†Ô∏è No visualizations generated: no suitable columns selected or found.\")\n",
    "    \n",
    "    print(f\"‚úÖ Saved {visual_count} plots -> {plot_folder}\")\n",
    "\n",
    "\n",
    "def generate_ydata_report(df: pd.DataFrame, base_filename: str, output_folder: str):\n",
    "    \"\"\"\n",
    "    Generates a ydata-profiling HTML report.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to profile (original data is best).\n",
    "        base_filename (str): The base name for the output file.\n",
    "        output_folder (str): The directory to save the report in.\n",
    "    \"\"\"\n",
    "    print(\"üìë Generating interactive HTML report...\")\n",
    "    try:\n",
    "        with redirect_stdout(StringIO()):  # Suppress stdout to avoid ydata-sdk advertisement\n",
    "            profile = ProfileReport(df, title=f\"Profiling Report for {base_filename}\", explorative=True, progress_bar=False)\n",
    "            report_path = os.path.join(output_folder, f\"{base_filename}_report_{datetime.now().strftime('%Y%m%d')}.html\")\n",
    "            profile.to_file(report_path, silent=True)\n",
    "        print(f\"‚úÖ Saved HTML report -> {report_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not generate ydata-profiling report: {e}\")\n",
    "\n",
    "\n",
    "def save_outputs(df_cleaned: pd.DataFrame, base_filename: str, output_folder: str):\n",
    "    \"\"\"\n",
    "    Saves the cleaned DataFrame to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        df_cleaned (pd.DataFrame): The cleaned data.\n",
    "        base_filename (str): The base name for the output file.\n",
    "        output_folder (str): The directory to save the file in.\n",
    "    \"\"\"\n",
    "    print(\"üíæ Saving cleaned data...\")\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    cleaned_path = os.path.join(output_folder, f\"{base_filename}_cleaned_{timestamp}.xlsx\")\n",
    "    df_cleaned.to_excel(cleaned_path, index=False)\n",
    "    print(f\"‚úÖ Saved cleaned dataset -> {cleaned_path}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION SCRIPT\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the data processing workflow.\"\"\"\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    \n",
    "    selected_files = list_and_select_files(DATA_FOLDER)\n",
    "    if not selected_files:\n",
    "        print(\"\\nNo files selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    for file_path in selected_files:\n",
    "        base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        print(f\"\\n{'='*20} PROCESSING: {base_filename} {'='*20}\")\n",
    "        \n",
    "        # Load\n",
    "        raw_df = load_data(file_path)\n",
    "        if raw_df is None:\n",
    "            continue # Skip to next file if loading failed\n",
    "\n",
    "        # Clean and get column mapping\n",
    "        cleaned_df, column_mapping = clean_data(raw_df, {'missing_values': 'none', 'drop_duplicates': False})\n",
    "\n",
    "        # Get cleaning and visualization choices with cleaned column names\n",
    "        cleaning_choices = get_cleaning_choices(cleaned_df.columns)\n",
    "\n",
    "        # Apply user-selected cleaning\n",
    "        cleaned_df, _ = clean_data(cleaned_df, cleaning_choices)\n",
    "        \n",
    "        # Generate Outputs\n",
    "        save_outputs(cleaned_df, base_filename, OUTPUT_FOLDER)\n",
    "        generate_visualizations(\n",
    "            cleaned_df,\n",
    "            base_filename,\n",
    "            OUTPUT_FOLDER,\n",
    "            cleaning_choices['bar_columns'],\n",
    "            cleaning_choices['pie_columns']\n",
    "        )\n",
    "        generate_ydata_report(raw_df, base_filename, OUTPUT_FOLDER) # Profile raw data\n",
    "        \n",
    "    print(\"\\nüéâ Automation complete for all selected files!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b556f-1191-4bfe-aad0-1a546152313a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
